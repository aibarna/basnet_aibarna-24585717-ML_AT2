{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZSNYXxvQQCM"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from IPython.display import Image\n",
        "import lightgbm as lgb\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dYuCmQxQQCP"
      },
      "outputs": [],
      "source": [
        "# Load the data from CSV files\n",
        "sales = pd.read_csv(r'C:\\Users\\aibar\\Downloads\\sales_train.csv')\n",
        "cal = pd.read_csv(r'C:\\Users\\aibar\\Downloads\\calendar.csv')\n",
        "cal_events = pd.read_csv(r'C:\\Users\\aibar\\Downloads\\calendar_events.csv')\n",
        "prices = pd.read_csv(r'C:\\Users\\aibar\\Downloads\\items_weekly_sell_prices.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6qejDvbQQCP",
        "outputId": "ee340a68-2703-4b9e-f4c6-7d1b0ff02475"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           date    event_name_1 event_type_1  event_name_2 event_type_2\n",
            "157  2016-05-08    Mother's day     Cultural          None         None\n",
            "158  2016-05-30     MemorialDay     National          None         None\n",
            "159  2016-06-02  NBAFinalsStart     Sporting          None         None\n",
            "160  2016-06-07  Ramadan starts    Religious          None         None\n",
            "161  2016-06-19    Father's day     Cultural  NBAFinalsEnd     Sporting\n"
          ]
        }
      ],
      "source": [
        "# Group events by date\n",
        "grouped = cal_events.groupby('date')\n",
        "\n",
        "# Create empty lists to store event_name and event_type\n",
        "event_names = []\n",
        "event_types = []\n",
        "\n",
        "# Iterate through groups and collect events\n",
        "for date, group in grouped:\n",
        "    event_names.append(list(group['event_name']))\n",
        "    event_types.append(list(group['event_type']))\n",
        "\n",
        "# Create a new dataframe with the desired format\n",
        "new_cal_events = {'date': grouped.groups.keys(),\n",
        "            'event_name_1': [names[0] for names in event_names],\n",
        "            'event_type_1': [types[0] for types in event_types],\n",
        "            'event_name_2': [names[1] if len(names) > 1 else None for names in event_names],\n",
        "            'event_type_2': [types[1] if len(types) > 1 else None for types in event_types]}\n",
        "\n",
        "new_cal_events = pd.DataFrame(new_cal_events)\n",
        "\n",
        "# Reorder columns\n",
        "new_cal_events = new_cal_events[['date', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']]\n",
        "\n",
        "# Display the transformed dataframe\n",
        "#print(new_cal_events.tail())\n",
        "\n",
        "print(new_cal_events.tail())\n",
        "calendar = cal.merge(new_cal_events, on = 'date', how = 'left')\n",
        "calendar['date'] = pd.to_datetime(calendar['date'])\n",
        "from datetime import datetime\n",
        "\n",
        "# Extract weekday (e.g., 'Monday' for 1, 'Tuesday' for 2, etc.)\n",
        "calendar['weekday'] = calendar['date'].dt.strftime('%A')\n",
        "\n",
        "# Extract month (e.g., 'January' for 1, 'February' for 2, etc.)\n",
        "calendar['month'] = calendar['date'].dt.month\n",
        "\n",
        "# Extract year\n",
        "calendar['year'] = calendar['date'].dt.year\n",
        "\n",
        "def map_weekday_to_wday(weekday):\n",
        "    weekdays = ['Saturday', 'Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
        "    return weekdays.index(weekday) + 1\n",
        "\n",
        "# Apply the mapping function to create the 'wday' column\n",
        "calendar['wday'] = calendar['weekday'].apply(map_weekday_to_wday)\n",
        "\n",
        "calendar = calendar[['date', 'wm_yr_wk', 'weekday', 'wday', 'month', 'year', 'd', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']]\n",
        "# here i am converting NaN value to Not_event\n",
        "calendar.fillna('No_event',inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTnkAM-YQQCQ"
      },
      "outputs": [],
      "source": [
        "#Add zero sales for the remaining days 1542-1549 for test data\n",
        "for d in range(1542,1549):\n",
        "    col = 'd_' + str(d)\n",
        "    sales[col] = 0\n",
        "    sales[col] = sales[col].astype(np.int16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srz5BkdIQQCQ"
      },
      "outputs": [],
      "source": [
        "#9 #Downcasting all the dataframes in order to save memory\n",
        "def downcast(df):\n",
        "    cols = df.dtypes.index.tolist()\n",
        "    types = df.dtypes.values.tolist()\n",
        "    for i,t in enumerate(types):\n",
        "        if 'int' in str(t):\n",
        "            if df[cols[i]].min() > np.iinfo(np.int8).min and df[cols[i]].max() < np.iinfo(np.int8).max:\n",
        "                df[cols[i]] = df[cols[i]].astype(np.int8)\n",
        "            elif df[cols[i]].min() > np.iinfo(np.int16).min and df[cols[i]].max() < np.iinfo(np.int16).max:\n",
        "                df[cols[i]] = df[cols[i]].astype(np.int16)\n",
        "            elif df[cols[i]].min() > np.iinfo(np.int32).min and df[cols[i]].max() < np.iinfo(np.int32).max:\n",
        "                df[cols[i]] = df[cols[i]].astype(np.int32)\n",
        "            else:\n",
        "                df[cols[i]] = df[cols[i]].astype(np.int64)\n",
        "        elif 'float' in str(t):\n",
        "            if df[cols[i]].min() > np.finfo(np.float16).min and df[cols[i]].max() < np.finfo(np.float16).max:\n",
        "                df[cols[i]] = df[cols[i]].astype(np.float16)\n",
        "            elif df[cols[i]].min() > np.finfo(np.float32).min and df[cols[i]].max() < np.finfo(np.float32).max:\n",
        "                df[cols[i]] = df[cols[i]].astype(np.float32)\n",
        "            else:\n",
        "                df[cols[i]] = df[cols[i]].astype(np.float64)\n",
        "        elif t == object:\n",
        "            if cols[i] == 'date':\n",
        "                df[cols[i]] = pd.to_datetime(df[cols[i]], format='%Y-%m-%d')\n",
        "            else:\n",
        "                df[cols[i]] = df[cols[i]].astype('category')\n",
        "    return df\n",
        "\n",
        "sales = downcast(sales)\n",
        "prices = downcast(prices)\n",
        "calendar = downcast(calendar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9zrbyNMQQCQ"
      },
      "outputs": [],
      "source": [
        "#Add zero sales for the remaining days 1542-1549 for test data\n",
        "for d in range(1542,1549):\n",
        "    col = 'd_' + str(d)\n",
        "    sales[col] = 0\n",
        "    sales[col] = sales[col].astype(np.int16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZayvEnCQQCR"
      },
      "outputs": [],
      "source": [
        "# Melt the sales data to have a columnar format\n",
        "df_sales=pd.melt(sales, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name='d', value_name='sold')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUg9R0kkQQCR",
        "outputId": "9b2ab28c-802a-403b-f663-bdcc77bc52ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Perform garbage collection to free up memory\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "180qsHLdQQCR"
      },
      "outputs": [],
      "source": [
        "# Merge the sales data with the calendar data based on the 'd' column\n",
        "df_final= pd.merge(df_sales, calendar, on='d', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMzHFEKtQQCR",
        "outputId": "f8d5e32a-8943-41cf-b497-e4919b53f77f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Perform garbage collection to free up memory\n",
        "del cal\n",
        "del cal_events\n",
        "del date\n",
        "del event_names\n",
        "del event_types\n",
        "del group\n",
        "del grouped\n",
        "del new_cal_events\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unGfOiZNQQCS"
      },
      "outputs": [],
      "source": [
        "# Merge the df_final DataFrame with the prices DataFrame based on 'store_id', 'item_id', and 'wm_yr_wk'\n",
        "\n",
        "df_final= pd.merge(df_final, prices, on=['store_id','item_id','wm_yr_wk'], how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZ3WpjJTQQCS"
      },
      "outputs": [],
      "source": [
        "# Fill NaN values in the 'sell_price' column with the mean sell price for each store, item, and day\n",
        "\n",
        "df_final['sell_price'].fillna(df_final.groupby(['store_id','item_id','d'])['sell_price'].transform('mean'),inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6leeGQ99QQCS"
      },
      "outputs": [],
      "source": [
        "# Fill any remaining NaN values in the 'sell_price' column with 0\n",
        "df_final['sell_price'].fillna(0, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4PMfwDcQQCS"
      },
      "outputs": [],
      "source": [
        "# Calculate the revenue by multiplying 'sold' and 'sell_price' columns\n",
        "\n",
        "df_final['revenue'] = df_final['sold'] * df_final['sell_price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDNEWsGuQQCS"
      },
      "outputs": [],
      "source": [
        "# Convert 'revenue' column to integer data type\n",
        "df_final['revenue'] = df_final['revenue'].astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6Pi9if6QQCS"
      },
      "outputs": [],
      "source": [
        "# Dropping columns with more than 50% missing values as imputing them will not be a good option\n",
        "columns_to_drop = ['sold','wm_yr_wk', 'weekday', 'wday', 'month', 'year','item_id', 'dept_id', 'cat_id', 'state_id','event_name_1', 'event_type_1','event_name_2', 'event_type_2']\n",
        "\n",
        "# Use the drop method to remove the specified columns\n",
        "df_final = df_final.drop(columns=columns_to_drop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLU-MaaNQQCS"
      },
      "outputs": [],
      "source": [
        "# label encoding\n",
        "df_final.d = df_final['d'].apply(lambda x: x.split('_')[1]).astype(np.int16)\n",
        "cols = df_final.dtypes.index.tolist()\n",
        "types = df_final.dtypes.values.tolist()\n",
        "for i,type in enumerate(types):\n",
        "    if type.name == 'category':\n",
        "        df_final[cols[i]] = df_final[cols[i]].cat.codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ7X_gFjQQCS",
        "outputId": "e6da0bb0-1c99-488d-fdf8-8ac4b96d4bf2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>d</th>\n",
              "      <th>date</th>\n",
              "      <th>sell_price</th>\n",
              "      <th>revenue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14370</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14380</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14390</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14400</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14410</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  store_id  d       date  sell_price  revenue\n",
              "0  14370         0  1 2011-01-29         0.0        0\n",
              "1  14380         0  1 2011-01-29         0.0        0\n",
              "2  14390         0  1 2011-01-29         0.0        0\n",
              "3  14400         0  1 2011-01-29         0.0        0\n",
              "4  14410         0  1 2011-01-29         0.0        0"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUP1AP0hQQCS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "import statsmodels.api as sm\n",
        "import itertools\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0cxuYryQQCS"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_and_preprocess_data(data):\n",
        "    # Drop unnecessary columns and set the date as the index\n",
        "    data = data.groupby(['date', 'id', 'store_id', 'd'])['revenue'].sum().reset_index()\n",
        "    data = data.drop(columns=['id', 'store_id', 'd'])\n",
        "    data.set_index('date', inplace=True)\n",
        "\n",
        "    # Group data by date and sum the revenue\n",
        "    data = data.groupby(data.index).sum()\n",
        "    data.index = pd.to_datetime(data.index)\n",
        "\n",
        "    # Convert 'revenue' column to numeric type\n",
        "    data['revenue'] = pd.to_numeric(data['revenue'], errors='coerce')\n",
        "\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2D92c57-QQCT"
      },
      "outputs": [],
      "source": [
        "\n",
        "def test_stationarity(data):\n",
        "    # Perform Augmented Dickey-Fuller Test\n",
        "    dftest = adfuller(data, autolag='AIC')\n",
        "    print(\"1. ADF:\", dftest[0])\n",
        "    print(\"2. P-Value:\", dftest[1])\n",
        "    print(\"3. Num of Lags :\",dftest[2])\n",
        "    print(\"4. Num of observations used for ADF Regression and critical values Calculation :\", dftest[3])\n",
        "    print(\"5. Critical Values :\")\n",
        "    for key, val in dftest[4].items():\n",
        "        print(\"\\t\", key, \": \", val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KNT-sSGQQCT"
      },
      "outputs": [],
      "source": [
        "\n",
        "def difference_data(data):\n",
        "    # Calculate the difference between consecutive revenue values\n",
        "    data['revenue'] = data['revenue'] - data['revenue'].shift(1)\n",
        "    data = data.dropna()\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTqh1v4KQQCT"
      },
      "outputs": [],
      "source": [
        "\n",
        "def auto_arima_model(data):\n",
        "    p = d = q = range(0, 2)\n",
        "    pdq = list(itertools.product(p, d, q))\n",
        "    seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
        "\n",
        "    best_aic = float(\"inf\")\n",
        "    best_params = None\n",
        "    best_seasonal_params = None\n",
        "\n",
        "    for param in pdq:\n",
        "        for param_seasonal in seasonal_pdq:\n",
        "            try:\n",
        "                model = sm.tsa.statespace.SARIMAX(data,\n",
        "                                                order=param,\n",
        "                                                seasonal_order=param_seasonal,\n",
        "                                                enforce_stationarity=False,\n",
        "                                                enforce_invertibility=False)\n",
        "                results = model.fit()\n",
        "                aic = results.aic\n",
        "                if aic < best_aic:\n",
        "                    best_aic = aic\n",
        "                    best_params = param\n",
        "                    best_seasonal_params = param_seasonal\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "    return best_params, best_seasonal_params\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECysyH61QQCT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load and preprocess data\n",
        "\n",
        "total_revenue_df = load_and_preprocess_data(df_final)\n",
        "\n",
        "# Test stationarity\n",
        "test_stationarity(total_revenue_df['revenue'])\n",
        "\n",
        "# Difference the data\n",
        "total_revenue_df = difference_data(total_revenue_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_kW2s6SQQCT"
      },
      "outputs": [],
      "source": [
        "\n",
        " # Perform automated ARIMA modeling\n",
        "best_params, best_seasonal_params = auto_arima_model(total_revenue_df)\n",
        "print(\"Best ARIMA Parameters (p, d, q):\", best_params)\n",
        "print(\"Best Seasonal Parameters (P, D, Q, S):\", best_seasonal_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53zPR5B0QQCT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Split the data into training and validation sets\n",
        "training_data, validation_data = train_test_split(total_revenue_df, test_size=0.2, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0B0i50NTQQCT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Fit the best ARIMA model\n",
        "model = sm.tsa.statespace.SARIMAX(training_data,\n",
        "                                    order=best_params,\n",
        "                                    seasonal_order=best_seasonal_params,\n",
        "                                    enforce_stationarity=False,\n",
        "                                    enforce_invertibility=False)\n",
        "results = model.fit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTFU8K-HQQCT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Make predictions on the validation set\n",
        "forecast = results.get_forecast(steps=len(validation_data))\n",
        "forecasted_revenue = forecast.predicted_mean\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XB7gDnoAQQCT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Calculate RMSE on the validation set\n",
        "rmse_value = np.sqrt(mean_squared_error(valid_data['revenue'], forecasted_revenue))\n",
        "print(\"Validation RMSE:\", rmse_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee_NpdRbQQCT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Forecast sales for the next 7 days\n",
        "forecast = results.forecast(steps=7)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YdLp3hjQQCT",
        "outputId": "c22192f6-ac95-4489-9cd5-73ba84d57e0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2014-06-20    2239.969976\n",
              "2014-06-21    7927.344333\n",
              "2014-06-22    5399.822257\n",
              "2014-06-23   -4764.303182\n",
              "2014-06-24    -786.323513\n",
              "2014-06-25   -5865.924878\n",
              "2014-06-26   -3327.795587\n",
              "Freq: D, Name: predicted_mean, dtype: float64"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forecast"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}